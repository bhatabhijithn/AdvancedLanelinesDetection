{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tracker import tracker\n",
    "%matplotlib notebook\n",
    "\n",
    "#  from tracker import tracker\n",
    "\n",
    "#  read in the saved objpoints and imagepoints\n",
    "\n",
    "dist_pickle = pickle.load(open(\"calibration_pickle.p\", \"rb\"))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "\n",
    "    # Calculate gradient direction\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.cvtColor(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.cvtColor(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "        absgraddir = np.absolute(np.arctan(sobely/sobelx))\n",
    "        binary_output = np.zeros_like(absgraddir)\n",
    "        # Apply threshold\n",
    "        binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(image, orient='x', thresh=(0, 255)):\n",
    "    # Convert to Grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "    else:\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # create a copy and apply the threshold\n",
    "    binary_output = np.zeros_like(gray)#scaled_sobel)\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "    binary_output[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    #sxbinary     [(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    # sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    #print(\"binary_output\", binary_output)\n",
    "    #preprocessImage = np.zeros_like(gray)#image[:, :, 0])\n",
    "    #preprocessImage[(binary_output == 1)] = 255\n",
    "    #plt.imshow(binary_output)\n",
    "    #plt.title('window fitting results')\n",
    "    #plt.show()\n",
    "\n",
    "    #f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    #f.tight_layout()\n",
    "    ###ax1.imshow(image)\n",
    "    #ax1.set_title('Original Image', fontsize=50)\n",
    "    #ax2.imshow(scaled_sobel, cmap='gray')\n",
    "    #ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "    #plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "    #plt.imshow(preprocessImage, cmap='gray')\n",
    "    #cv2.imwrite('./sobeltest.jpg', binary_output)\n",
    "\n",
    "\n",
    "    return binary_output# preprocessImage\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(image,  cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # take derivative in x and y direction\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the Gradient max\n",
    "    gradmax = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # scale to 8bit (0-255) then convert to uint8\n",
    "    scaled_sobel = np.uint8(255*gradmax/np.max(gradmax))\n",
    "\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(sxbinary >= mag_thresh[0]) & (sxbinary <= mag_thresh[1])]\n",
    "    return sxbinary\n",
    "\n",
    "def color_threshold(image, sthresh=(0, 255), vthresh=(0, 255)):\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)#.astype(np.float)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:, :, 2]\n",
    "    #sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    #abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    #scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= sthresh[0]) & (s_channel <= sthresh[1])] = 1\n",
    "\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float)\n",
    "    v_channel = hsv[:, :, 2]\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel >= vthresh[0]) & (v_channel <= vthresh[1])] = 1\n",
    "    #print(\"V\", v_binary)\n",
    "\n",
    "    output = np.zeros_like(s_channel)\n",
    "    output[(s_binary == 1) & (v_binary == 1)] = 1\n",
    "    return output\n",
    "    \n",
    "\n",
    "def window_mask(width, height, img_ref, center,level):\n",
    "    output = np.zeros_like(img_ref)\n",
    "    output[int(img_ref.shape[0]-(level+1)*height):int(img_ref.shape[0]-level*height),max(0,int(center-width/2)):min(int(center+width/2),img_ref.shape[1])] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def visualize(image):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(image, cmap='gray')\n",
    "    ax2.set_title('Thresholded Magnitude', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 416.5  929.5]\n",
      " [ 417.5  926.5]\n",
      " [ 416.5  931.5]\n",
      " [ 413.5  933.5]\n",
      " [ 413.5  908.5]\n",
      " [ 414.5  883.5]\n",
      " [ 414.5  858.5]\n",
      " [ 414.5  833.5]\n",
      " [ 416.5  808.5]\n",
      " [ 413.5  783.5]\n",
      " [ 417.5  758.5]\n",
      " [ 417.5  733.5]\n",
      " [ 418.5  708.5]\n",
      " [ 416.5  683.5]\n",
      " [ 419.5  658.5]\n",
      " [ 415.5  633.5]\n",
      " [ 422.5  608.5]\n",
      " [ 423.5  583.5]]\n",
      "L point (720, 1280)\n",
      "R point (720, 1280)\n",
      "template2 (720, 1280, 3)\n",
      "[[ 441.5  910.5]\n",
      " [ 443.5  908.5]\n",
      " [ 442.5  906.5]\n",
      " [ 440.5  902.5]\n",
      " [ 438.5  902.5]\n",
      " [ 436.5  900.5]\n",
      " [ 434.5  875.5]\n",
      " [ 432.5  850.5]\n",
      " [ 936.5  825.5]\n",
      " [ 934.5  800.5]\n",
      " [ 932.5  775.5]\n",
      " [ 935.5  750.5]\n",
      " [ 939.5  725.5]\n",
      " [ 914.5  700.5]\n",
      " [ 889.5  675.5]\n",
      " [ 906.5  650.5]\n",
      " [ 915.5  625.5]\n",
      " [ 923.5  600.5]]\n",
      "L point (720, 1280)\n",
      "R point (720, 1280)\n",
      "template2 (720, 1280, 3)\n",
      "[[ 419.5  923.5]\n",
      " [ 417.5  921.5]\n",
      " [ 419.5  924.5]\n",
      " [ 421.5  926.5]\n",
      " [ 424.5  901.5]\n",
      " [ 426.5  876.5]\n",
      " [ 430.5  851.5]\n",
      " [ 433.5  826.5]\n",
      " [ 438.5  801.5]\n",
      " [ 440.5  776.5]\n",
      " [ 443.5  751.5]\n",
      " [ 446.5  726.5]\n",
      " [ 450.5  701.5]\n",
      " [ 454.5  676.5]\n",
      " [ 457.5  651.5]\n",
      " [ 461.5  626.5]\n",
      " [ 464.5  601.5]\n",
      " [ 470.5  576.5]]\n",
      "L point (720, 1280)\n",
      "R point (720, 1280)\n",
      "template2 (720, 1280, 3)\n",
      "[[ 429.5  945.5]\n",
      " [ 429.5  946.5]\n",
      " [ 428.5  921.5]\n",
      " [ 428.5  896.5]\n",
      " [ 429.5  871.5]\n",
      " [ 433.5  846.5]\n",
      " [ 429.5  821.5]\n",
      " [ 430.5  801.5]\n",
      " [ 431.5  776.5]\n",
      " [ 430.5  783.5]\n",
      " [ 428.5  784.5]\n",
      " [ 429.5  759.5]\n",
      " [ 426.5  734.5]\n",
      " [ 424.5  709.5]\n",
      " [ 425.5  684.5]\n",
      " [ 425.5  659.5]\n",
      " [ 425.5  634.5]\n",
      " [ 423.5  609.5]]\n",
      "L point (720, 1280)\n",
      "R point (720, 1280)\n",
      "template2 (720, 1280, 3)\n",
      "[[ 377.5  923.5]\n",
      " [ 377.5  920.5]\n",
      " [ 377.5  922.5]\n",
      " [ 377.5  925.5]\n",
      " [ 377.5  927.5]\n",
      " [ 377.5  930.5]\n",
      " [ 374.5  905.5]\n",
      " [ 390.5  880.5]\n",
      " [ 367.5  855.5]\n",
      " [ 382.5  830.5]\n",
      " [ 389.5  805.5]\n",
      " [ 385.5  780.5]\n",
      " [ 375.5  755.5]\n",
      " [ 407.5  730.5]\n",
      " [ 407.5  705.5]\n",
      " [ 961.5  680.5]\n",
      " [ 964.5  655.5]\n",
      " [ 969.5  630.5]]\n",
      "L point (720, 1280)\n",
      "R point (720, 1280)\n",
      "template2 (720, 1280, 3)\n",
      "[[  431.5   945.5]\n",
      " [  430.5   920.5]\n",
      " [  432.5   944.5]\n",
      " [  434.5   919.5]\n",
      " [  437.5   894.5]\n",
      " [  440.5   869.5]\n",
      " [  443.5   844.5]\n",
      " [  445.5   819.5]\n",
      " [  449.5   794.5]\n",
      " [  968.5   769.5]\n",
      " [  975.5   744.5]\n",
      " [ 1083.5   719.5]\n",
      " [ 1096.5   694.5]\n",
      " [ 1094.5   669.5]\n",
      " [ 1142.5   644.5]\n",
      " [ 1182.5   619.5]\n",
      " [ 1266.5   594.5]\n",
      " [ 1266.5   569.5]]\n",
      "L point (720, 1280)\n",
      "R point (720, 1280)\n",
      "template2 (720, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "from tracker import tracker\n",
    "images = glob.glob('./test_images/test*.jpg')\n",
    "for idx, fname in enumerate(images):\n",
    "    # read the image\n",
    "    img = cv2.imread(fname)\n",
    "    # undistort the images\n",
    "    img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # print(img)\n",
    "\n",
    "    # process image and generate binary pixel of interest\n",
    "    preprocessImage = np.zeros_like(img[:, :, 0])\n",
    "    gradx = abs_sobel_thresh(img, orient='x', thresh=(12, 255)) #20, 120\n",
    "    # print(gradx)\n",
    "    grady = abs_sobel_thresh(img, orient='y', thresh=(25, 255)) #25, 150\n",
    "    c_binary = color_threshold(img, sthresh=(100, 255), vthresh=(50, 255))#170,255\n",
    "    #print(c_binary)\n",
    "    preprocessImage[((gradx ==1)&(grady == 1))|(c_binary == 1)] = 255\n",
    "    \n",
    "    #Define perspective transform\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    bot_width = .76 #% of bottom trapeziodal width\n",
    "    mid_width = .16   #% of middle trapezoidal width\n",
    "    height_pct = .66 #% of trapezoidal height\n",
    "    bottom_trim = .935 #% to avoid car hood\n",
    "    src = np.float32([[img.shape[1]*(.5-mid_width/2), img.shape[0]*height_pct], \n",
    "                      [img.shape[1]*(.5+mid_width/2), img.shape[0]*height_pct],\n",
    "                      [img.shape[1]*(.5+bot_width/2), img.shape[0]*bottom_trim], \n",
    "                      [img.shape[1]*(.5-bot_width/2), img.shape[0]*bottom_trim],])\n",
    "    offset = img_size[0]*.25\n",
    "    dst = np.float32([[offset, 0], \n",
    "                      [img_size[0]-offset, 0], \n",
    "                      [img_size[0]-offset, img_size[1]],\n",
    "                      [offset, img_size[1]]])\n",
    "    #print(\"src\", src)\n",
    "    #print(\"dst\", dst)\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(preprocessImage, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    window_width = 25\n",
    "    window_height = 40\n",
    "    #Set up the overall class to do all the tracking\n",
    "    curve_centers = tracker(Mywindow_width = window_width, Mywindow_height = window_height, Mymargin = 25, My_ym = 10/720, My_xm = 4/384, Mysmooth_factor = 15)\n",
    "    window_centroids = []\n",
    "    window_centroids = curve_centers.find_window_centroids(warped)\n",
    "    print(window_centroids)\n",
    "    \n",
    "    #Points used to draw all the left and right windows\n",
    "    l_points = np.zeros_like(warped)\n",
    "    r_points = np.zeros_like(warped)\n",
    "    \n",
    "    \n",
    "    rightx = []\n",
    "    leftx = []\n",
    "    \n",
    "    \n",
    "    for level in range(0,len(window_centroids)):\n",
    "        # Window_mask is a function to draw window areas\n",
    "        # Add center value found in frame to the list of lane points per left, right\n",
    "        leftx.append(window_centroids[level][0])\n",
    "        rightx.append(window_centroids[level][1])\n",
    "\n",
    "        l_mask = window_mask(window_width,window_height,warped,window_centroids[level][0],level)\n",
    "        r_mask = window_mask(window_width,window_height,warped,window_centroids[level][1],level)\n",
    "        # Add graphic points from window mask here to total pixels found \n",
    "        l_points[(l_points == 255) | ((l_mask == 1) ) ] = 255\n",
    "        r_points[(r_points == 255) | ((r_mask == 1) ) ] = 255\n",
    "        \n",
    "    print(\"L point\", l_points.shape)\n",
    "    print(\"R point\", l_points.shape)\n",
    "    \n",
    "\n",
    "    # Draw the results\n",
    "    template = np.array(r_points+l_points,np.uint8) # add both left and right window pixels together\n",
    "    #print(\"template\", template.shape)\n",
    "    zero_channel = np.zeros_like(template) # create a zero color channel\n",
    "    #print(\"zero channel\", zero_channel.shape)\n",
    "    template = np.array(cv2.merge((zero_channel,template,zero_channel)),np.uint8) # make window pixels green\n",
    "    #visualize(template)\n",
    "    print(\"template2\", template.shape)\n",
    "    warpage= np.dstack((warped, warped, warped))*255 # making the original road pixels 3 color channels\n",
    "    #print(\"warpage\", warpage.shape)\n",
    "    output = cv2.addWeighted(warpage, 1, template, 0.5, 0.0) # overlay the orignal road image with window results\n",
    "    \n",
    "    #Fit the lane boundaries to the left , right center positions found\n",
    "    yvals = range(0, warped.shape[0])\n",
    "    res_yvals = np.arange(warped.shape[0]-(window_height/2),0,-window_height)\n",
    "    \n",
    "    left_fit =np.polyfit(res_yvals, leftx, 2)\n",
    "    left_fitx = left_fit[0]*yvals*yvals + left_fit[1]*yvals + left_fit[2]\n",
    "    left_fitx = np.array(left_fitx, np.int32)\n",
    "    \n",
    "    right_fit = np.polyfit(res_yvals, rightx, 2)\n",
    "    right_fitx = right_fit[0]*yvals*yvals + right_fit[1]*yvals + right_fit[2]\n",
    "    right_fitx = np.array(right_fitx, np.int32)\n",
    "    \n",
    "    left_lane = np.array(list(zip(np.concatenate((left_fitx-window_width/2,left_fitx[::-1]+window_width/2), axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    right_lane = np.array(list(zip(np.concatenate((right_fitx-window_width/2,right_fitx[::-1]+window_width/2), axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    inner_lane = np.array(list(zip(np.concatenate((left_fitx+window_width/2,right_fitx[::-1]-window_width/2), axis=0),np.concatenate((yvals,yvals[::-1]),axis=0))),np.int32)\n",
    "    #curve_pts = np.array[list(zip(curve_fit)))\n",
    "    \n",
    "    road = np.zeros_like(img)\n",
    "    cv2.fillPoly(road, [left_lane], color=[255,0,0])\n",
    "    cv2.fillPoly(road, [right_lane], color=[0,0,255])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    result = road\n",
    "    #print(\"result\", result.shape)\n",
    "    write_name = './test_images/tracked' + str(idx) + '.jpg'\n",
    "    cv2.imwrite(write_name, result)\n",
    "    #exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://github.com/awbrown90/Advance-Lane-Finding/blob/master/main_image_gen.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
